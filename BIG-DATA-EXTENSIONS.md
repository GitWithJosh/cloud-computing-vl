# ğŸ—‚ï¸ğŸ“Š Big Data Erweiterungen: Aufgabe 4

> **Cloud Computing und Big Data - Portfolio-PrÃ¼fung**  
> Erweiterte Implementierung mit Data Lake, Stream Processing und ML

---

## ğŸ¯ **Ãœberblick der Erweiterungen**

### **Aufgabe 4: Data Lake / Big Data-Processing** âœ… **VOLLSTÃ„NDIG IMPLEMENTIERT**
- âœ… **Verteilter Data Lake**: MinIO (S3-kompatibel) fÃ¼r Object Storage
- âœ… **Big Data Processing**: Python ML Jobs auf Kubernetes
- âœ… **Machine Learning**: scikit-learn fÃ¼r Food Calorie Analysis
- âœ… **Bonus Features**: Cloud-native Stack, horizontale Skalierung

---

## ğŸš€ **Quick Start fÃ¼r Aufgabe 4**

### **Setup Data Lake & Batch Processing**
```bash
# âš ï¸  WICHTIG: Befehle in dieser Reihenfolge ausfÃ¼hren!

# 1. Data Lake installieren (ZUERST - erstellt big-data namespace + MinIO)
./version-manager.sh setup-datalake

# 2. ML Pipeline starten (benÃ¶tigt setup-datalake!) 
./version-manager.sh ml-pipeline

# 3. Status prÃ¼fen (SSH erforderlich)
ssh -i ~/.ssh/$ssh_key ubuntu@$master_ip kubectl get pods -n big-data
ssh -i ~/.ssh/$ssh_key ubuntu@$master_ip kubectl get jobs -n big-data
```